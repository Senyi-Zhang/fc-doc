## Module 3: Evidence-Claim Relevance Analysis

### 1. Goal and Importance

The primary goal of Module 3 is to critically assess whether the evidence snippets retrieved by Module 2 are semantically relevant to the specific factual assertion made in the input `claim_text`. This is a crucial filtering step to ensure that only pertinent information proceeds to Module 4 for the actual verification process. Passing irrelevant evidence downstream would lead to incorrect verification outcomes and wasted computational resources.

### 2. Core Technology: Leveraging Large Language Models (LLMs)

This module heavily relies on the advanced natural language understanding (NLU) and natural language inference (NLI) capabilities of LLMs. As anticipated, determining semantic relevance between two pieces of text (the claim and the potential evidence) is a task where LLMs demonstrate strong performance. They can:

* Understand the core meaning and intent behind both the claim and the evidence.
* Go beyond simple keyword matching to identify contextual and semantic relationships.
* Recognize nuances, synonymy, and implied meanings that are critical for accurate relevance assessment.

### 3. Process Overview

1.  **Input:**
    * The original `claim_text` (from Module 1).
    * A `retrieved_evidence_snippet` (including its source, e.g., URL/article title, provided by Module 2). This process is typically performed for each snippet retrieved in a batch from Module 2.

2.  **LLM Task & Prompting Strategy:**
    * The LLM is provided with both the `claim_text` and the `evidence_snippet`.
    * A carefully crafted prompt instructs the LLM to determine if the `evidence_snippet` directly pertains to, and could potentially help verify or refute, the factual assertion made in the `claim_text`.
    * The LLM is typically asked to output:
        * A clear relevance judgment (e.g., "Relevant," "Not Relevant"). A "Partially Relevant" or "Uncertain" category might also be used, potentially with different downstream handling.
        * (Recommended) A brief justification for its decision, particularly if the evidence is deemed "Not Relevant." This aids in system debugging, performance analysis, and potential refinement of Module 2's retrieval strategies.

3.  **Output:**
    * For each evidence snippet: A relevance status (e.g., `is_relevant: true/false`).
    * The module will pass forward only those evidence snippets identified as "Relevant."
    * (Optional) The LLM's rationale for its judgments.

### 4. Key Considerations

While LLMs significantly simplify this task, certain aspects require attention:

* **Defining "Relevance" for Fact-Checking:** The prompt must clearly define what constitutes actionable relevance. For instance, the evidence should not just be about the same general topic or entities but must address the specific factual core of the claim.
* **Handling Nuance and Ambiguity:** While LLMs are generally robust, prompts may need iterative tuning to handle subtle cases of irrelevance or highly nuanced claims effectively.
* **Confidence Thresholds (Optional):** If the LLM provides a confidence score for its relevance assessment, a system-defined threshold can be used to make the final relevance decision.
* **Feedback Loop to Module 2:** If none of the evidence snippets in a batch from Module 2 are deemed relevant, Module 3 signals this outcome. This feedback is critical for triggering the re-retrieval mechanisms in Module 2, prompting it to try different queries or sources.

### 5. Expected Outcome

The successful execution of Module 3 results in a curated list of evidence snippets that are highly pertinent to the claim under investigation. This filtered set is then passed to Module 4, providing a solid and focused foundation for the final claim verification step