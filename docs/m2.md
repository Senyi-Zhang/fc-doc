## Module 2: Evidence Retrieval (Wikipedia API Focused)

### 1. Goal and Approach

The primary function of Module 2 is to retrieve relevant textual evidence for atomic claims (provided by Module 1) by querying the live Wikipedia database. This approach leverages Wikipedia's extensive, continuously updated, and semi-structured knowledge base without requiring a local data store.

The core strategy relies on interacting with the official **MediaWiki API** for the relevant language edition of Wikipedia (e.g., `en.wikipedia.org`). Retrieval is enhanced by **Large Language Models (LLMs)** which assist in query formulation, entity linking, and processing the retrieved content to extract precise evidence snippets.

### 2. Core Strategy: Tiered Retrieval Attempts

Evidence retrieval operates iteratively. If initial attempts fail to yield relevant evidence (as determined by Module 3: Evidence Relevance Analysis), the system escalates through a series of increasingly sophisticated attempts. State is maintained for each claim, tracking the `attempt_count`, `tried_wikipedia_titles`, and `tried_search_terms` to ensure diversity and avoid redundant searches.

**Attempt 1: Direct Entity Matching & Focused Search**

1.  **Claim Analysis & Query Generation (LLM-assisted):**
    * The LLM analyzes the input `claim_text` to identify key entities and concepts.
    * It predicts the most likely corresponding Wikipedia article title(s) for the main entities.
    * Generates 1-2 initial queries:
        * **Title Query:** Directly attempts to fetch the introduction (`prop=extracts&exintro=true&explaintext=true`) of the highest-probability article title identified.
        * **Keyword Search Query:** Uses core entities and keywords in a `list=search` API call to find the top M (e.g., 3-5) relevant articles.
    * These initial targets (titles/search terms) are recorded.

2.  **Wikipedia API Interaction:**
    * Execute the generated queries via the MediaWiki API.
    * For titles returned by `list=search`, fetch their introductory extracts.

3.  **Initial Snippet Extraction:**
    * The retrieved introductory text often serves as a good initial snippet.
    * Optionally, an LLM refines this by extracting the 1-3 sentences most directly pertinent to the input `claim_text` from the retrieved extract.

4.  **Output:** A list of potential evidence snippets `[{wikipedia_article_title, relevant_snippet, wikipedia_url}, ...]` is passed to Module 3.

**Attempt 2: Broader Search & Section Exploration (if Attempt 1 fails)**

1.  **Query/Strategy Refinement (LLM-assisted):**
    * The LLM receives the `claim_text`, the failed queries/titles from Attempt 1, and optionally feedback from Module 3.
    * **LLM Task:** Generate new, broader, or alternative keyword search terms for `list=search`. If a generally relevant article was identified in Attempt 1 but the introduction was insufficient, the LLM suggests specific section titles within that article (e.g., "History," "Controversies," "Technical specifications") likely to contain the needed information.
    * New search terms are recorded.

2.  **Wikipedia API Interaction:**
    * Execute new keyword searches.
    * If exploring sections:
        * Use the API to fetch the full article text (`prop=extracts&explaintext=true`) or specific sections (e.g., via `action=parse&prop=text&section=...` followed by HTML-to-text conversion, or by parsing the full text).

3.  **Enhanced Snippet Extraction (LLM-assisted):**
    * Since larger text blocks (full articles or sections) might be retrieved, the LLM plays a crucial role in scanning this text and extracting only the highly relevant sentences pertaining to the `claim_text`.

4.  **Output:** Evidence snippets passed to Module 3.

**Attempt 3: Leveraging Wikipedia Structure (if Attempts 1 & 2 fail)**

1.  **Strategy Adjustment (LLM-assisted):**
    * If a partially relevant article was identified but lacked direct evidence, the LLM analyzes its structure.
    * **LLM Task:** Based on the `claim_text` and the partially relevant article's title, identify the most promising "Categories" the article belongs to, or relevant article titles listed in its "See also" section.

2.  **Wikipedia API Interaction:**
    * Retrieve categories for the partially relevant article (`prop=categories`).
    * Retrieve "See also" links (often requires parsing the article content).
    * Based on LLM recommendations, perform new searches within promising categories or directly retrieve content for suggested "See also" articles.

3.  **Snippet Extraction:** As per previous attempts, using LLM assistance.

4.  **Output:** Evidence snippets passed to Module 3.

### 3. Handling Wikipedia Specifics

The system incorporates logic to handle common Wikipedia features:

* **Disambiguation Pages:** If an API query returns a disambiguation page, the options are presented (potentially to an LLM) to select the most relevant target entity based on the original claim's context, triggering a follow-up query for the correct title.
* **Redirects:** The MediaWiki API typically handles redirects transparently when fetching page content by title.
* **Content Volume:** Priority is given to introductory sections and specific relevant sections identified by the LLM to manage potentially large article sizes and LLM context window limitations.

### 4. Role of Large Language Models (LLMs)

Throughout the retrieval process, LLMs act as an "intelligent assistant" to:
* **Understand Claims:** Parse the input claim to identify key semantic components.
* **Link Entities:** Map entities in the claim to potential Wikipedia article titles.
* **Generate Queries:** Create effective search terms and API query parameters.
* **Refine Strategy:** Suggest alternative search angles, broader terms, or relevant sections when initial attempts fail.
* **Extract Snippets:** Pinpoint and extract the most relevant sentences from potentially lengthy Wikipedia text.

### 5. API Usage Considerations

* **Language:** API calls are directed to the appropriate language version of Wikipedia (e.g., `en.wikipedia.org`).
* **Rate Limiting & Identification:** Adhere to MediaWiki API usage policies, including rate limits and providing a descriptive User-Agent string in requests.
* **Content Dynamism:** Recognize that Wikipedia content can change; retrieved evidence reflects the state of the article at the time of the query. Logging timestamps and source URLs is essential.

### 6. Failure Condition

If all tiered retrieval attempts up to the defined `MAX_ATTEMPTS` (e.g., 3 or 4) fail to produce evidence deemed relevant by Module 3, Module 2 reports a failure status for the claim (e.g., "EVIDENCE_RETRIEVAL_FAILED_WIKIPEDIA").